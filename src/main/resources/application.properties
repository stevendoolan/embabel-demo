# When using @EnableAgents(localModels = {LocalModels.OLLAMA},loggingTheme = LoggingThemes.STAR_WARS)

# To my knowledge OpenAI themselves don't host GPT-OSS, however it available as a local model or via various providers
# such as GROQ (https://groq.com/). Since Groq API is open-ai compatible one could use OpenAiCompatibleModelFactory
# to register a model, usings Groq's baseURL as the base.

# Use Ollama for gpt-oss: ollama run gpt-oss
embabel.models.defaultLlm=gpt-oss:latest
#embabel.models.defaultEmbeddingModel=nomic-embed-text:latest
#
#embabel.models.llms.best=llama3.1:8b
#embabel.models.llms.cheapest=llama3.1:8b
#
#embabel.models.embeddingServices.best=nomic-embed-text:latest
#embabel.models.embeddingServices.cheapest=nomic-embed-text:latest
#
#embabel.agent-platform.ranking.llm=llama3.1:8b
