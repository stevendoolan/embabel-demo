# When using @EnableAgents(localModels = {LocalModels.OLLAMA},loggingTheme = LoggingThemes.STAR_WARS)

# To my knowledge OpenAI themselves don't host GPT-OSS, however it available as a local model or via various providers
# such as GROQ (https://groq.com/). Since Groq API is open-ai compatible one could use OpenAiCompatibleModelFactory
# to register a model, usings Groq's baseURL as the base.

# Use Ollama for gpt-oss: ollama run gpt-oss
embabel.models.defaultLlm=gpt-oss:latest
embabel.models.llms.best=gpt-oss:latest
embabel.models.llms.cheapest=gpt-oss:latest